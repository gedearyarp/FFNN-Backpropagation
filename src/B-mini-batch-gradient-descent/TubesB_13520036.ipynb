{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar B\n",
    "IF3270 Pembelajaran Mesin<br>\n",
    "Backward Propagation - Mini Batch Gradient Descent\n",
    "\n",
    "Developed by:\n",
    "1. K01 13520010 - Ken Kalang Al Qalyubi\n",
    "2. K01 13520036 - I Gede Arya Raditya Parameswara\n",
    "3. K02 13520061 - Gibran Darmawan\n",
    "4. K03 13520119 - Marchotridyo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerEnum(Enum):\n",
    "    INPUT = \"INPUT\"\n",
    "    HIDDEN = \"HIDDEN\"\n",
    "    OUTPUT = \"OUTPUT\"\n",
    "\n",
    "class ActivationFuncEnum(Enum):\n",
    "    SIGMOID = \"SIGMOID\"\n",
    "    LINEAR = \"LINEAR\"\n",
    "    RELU = \"RELU\"\n",
    "    SOFTMAX = \"SOFTMAX\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtility:\n",
    "    @staticmethod\n",
    "    def import_json(file_name):\n",
    "        with open(file_name) as json_file:\n",
    "            return json.load(json_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def export_json(file_name, data):\n",
    "        with open(file_name, 'w') as outfile:\n",
    "            json.dump(data, outfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    # Layer adalah kelas yang menyimpan sejumlah neutron berikut fungsi aktivasinya\n",
    "    def __init__(self, neurons: list, type: str, activation_func: str):\n",
    "        self.__neurons = neurons\n",
    "        self.__type = type\n",
    "        self.__activation_func = activation_func\n",
    "\n",
    "    def add_neuron(self, neuron):\n",
    "        self.__neurons.append(neuron)\n",
    "\n",
    "    def get_neurons(self):\n",
    "        return self.__neurons\n",
    "    \n",
    "    def get_type(self):\n",
    "        return self.__type\n",
    "    \n",
    "    def get_activation_func(self):\n",
    "        return self.__activation_func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(\n",
    "        self, \n",
    "        layer: Layer,\n",
    "        weight: list,\n",
    "        bias: list, \n",
    "    ):\n",
    "        self.__layer: Layer = layer\n",
    "        self.__weight: list = weight\n",
    "        self.__bias: list = bias\n",
    "        self.__net: float = 0.0\n",
    "        self.__value: float = 0.0\n",
    "\n",
    "    def activate(self):\n",
    "        if self.__layer.get_activation_func() == ActivationFuncEnum.SIGMOID.value:\n",
    "            self.__value = 1 / (1 + math.exp(-self.__net))\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.LINEAR.value:\n",
    "            self.__value = self.__net\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.RELU.value:\n",
    "            self.__value = max(0, self.__net)\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.SOFTMAX.value:\n",
    "            layer_neurons: list = self.__layer.get_neurons()\n",
    "            exp_sum: float = 0.0\n",
    "\n",
    "            for neuron in layer_neurons:\n",
    "                exp_sum += math.exp(neuron.get_net())\n",
    "\n",
    "            self.__value = math.exp(self.__net) / exp_sum\n",
    "\n",
    "    def set_value(self, value):\n",
    "        self.__value = value\n",
    "\n",
    "    def set_net(self, net):\n",
    "        self.__net = net\n",
    "\n",
    "    def get_value(self):\n",
    "        return self.__value\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.__net\n",
    "\n",
    "    def get_weight(self, index):\n",
    "        return self.__weight[index]\n",
    "\n",
    "    def get_bias(self):\n",
    "        return self.__bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNGraph:\n",
    "    def __init__(self, file_config_path: str):\n",
    "        self.file_path = file_config_path\n",
    "        self.config = None\n",
    "\n",
    "        self.layers: list[Layer] = []\n",
    "        self.build_ann_graph()\n",
    "\n",
    "    def build_ann_graph(self):\n",
    "        self.config = FileUtility.import_json(self.file_path)\n",
    "        layers = self.config[\"layers\"]\n",
    "\n",
    "        for layer in layers:\n",
    "            # Untuk setiap layer, persiapkan neuronnya\n",
    "            curr_layer = Layer([], layer[\"type\"], layer[\"activation_func\"])\n",
    "\n",
    "            for neuron_data in layer[\"neurons\"]:\n",
    "                neuron = self.__generate_neuron_data(curr_layer, neuron_data)\n",
    "                curr_layer.add_neuron(neuron)\n",
    "\n",
    "            self.layers.append(curr_layer)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def draw_ann_graph(self):\n",
    "        # Terminologies:\n",
    "        # Xi = neuron ke-i di input layer\n",
    "        # Hij = neuron ke-j di hidden layer ke-i\n",
    "        # Oi = neuron ke-i di output layer\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "\n",
    "        # Proses setiap layer\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                continue\n",
    "\n",
    "            prev_layer = self.layers[i - 1]\n",
    "            prev_prefix = \"\"\n",
    "            prefix = \"\"\n",
    "\n",
    "            if prev_layer.get_type() == LayerEnum.INPUT.value:\n",
    "                prev_prefix = \"X\"\n",
    "            elif prev_layer.get_type() == LayerEnum.HIDDEN.value:\n",
    "                prev_prefix = f\"H{i - 1}\"\n",
    "            else:\n",
    "                prev_prefix = \"O\"\n",
    "            \n",
    "            if layer.get_type() == LayerEnum.INPUT.value:\n",
    "                prefix = \"X\"\n",
    "            elif layer.get_type() == LayerEnum.HIDDEN.value:\n",
    "                prefix = f\"H{i}\"\n",
    "            else:\n",
    "                prefix = \"O\"\n",
    "\n",
    "            # Tambahkan edge dari setiap neuron di prev_layer ke layer\n",
    "            for j, _ in enumerate(prev_layer.get_neurons()):\n",
    "                for k, neuron in enumerate(layer.get_neurons()):\n",
    "                    if j == 0:\n",
    "                        print(f\"Bobot bias untuk {prefix}{k + 1} = {neuron.get_weight(0)}\")\n",
    "                    G.add_edge(f\"{prev_prefix}{j + 1}\", f\"{prefix}{k + 1}\", weight=neuron.get_weight(j + 1))\n",
    "            \n",
    "        # Set posisi node graph\n",
    "        pos = {}\n",
    "        curr_x = 0\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            curr_y = 0\n",
    "\n",
    "            prefix = \"\"\n",
    "            if layer.get_type() == LayerEnum.INPUT.value:\n",
    "                prefix = \"X\"\n",
    "            elif layer.get_type() == LayerEnum.HIDDEN.value:\n",
    "                prefix = f\"H{i}\"\n",
    "            else:\n",
    "                prefix = \"O\"\n",
    "            \n",
    "            for j, _ in enumerate(layer.get_neurons()):\n",
    "                pos[f\"{prefix}{j + 1}\"] = (curr_x, curr_y)\n",
    "                curr_y += 1\n",
    "\n",
    "            curr_x += 1\n",
    "\n",
    "        options = {\n",
    "            \"font_size\": 12,\n",
    "            \"node_size\": 2000,\n",
    "            \"node_color\": \"white\",\n",
    "            \"edgecolors\": \"black\",\n",
    "            \"linewidths\": 5,\n",
    "            \"width\": 5,\n",
    "        }\n",
    "\n",
    "        nx.draw_networkx(G, pos, **options)\n",
    "        edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels, label_pos=0.6)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.margins(0.2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
