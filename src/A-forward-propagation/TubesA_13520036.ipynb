{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar A\n",
    "IF3270 Pembelajaran Mesin<br>\n",
    "Forward Propagation - Feed Forward Neural Network (FFNN)\n",
    "\n",
    "Developed by:\n",
    "1. K01 13520010 - Ken Kalang Al Qalyubi\n",
    "2. K01 13520036 - I Gede Arya Raditya Parameswara\n",
    "3. K02 13520061 - Gibran Darmawan\n",
    "4. K03 13520119 - Marchotridyo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "from enum import Enum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerEnum(Enum):\n",
    "    INPUT = \"INPUT\"\n",
    "    HIDDEN = \"HIDDEN\"\n",
    "    OUTPUT = \"OUTPUT\"\n",
    "\n",
    "class ActivationFuncEnum(Enum):\n",
    "    SIGMOID = \"SIGMOID\"\n",
    "    LINEAR = \"LINEAR\"\n",
    "    RELU = \"RELU\"\n",
    "    SOFTMAX = \"SOFTMAX\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtility:\n",
    "    @staticmethod\n",
    "    def import_json(file_name):\n",
    "        with open(file_name) as json_file:\n",
    "            return json.load(json_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def export_json(file_name, data):\n",
    "        with open(file_name, 'w') as outfile:\n",
    "            json.dump(data, outfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    # Layer adalah kelas yang menyimpan sejumlah neutron berikut fungsi aktivasinya\n",
    "    def __init__(self, neurons: list, type: str, activation_func: str):\n",
    "        self.__neurons = neurons\n",
    "        self.__type = type\n",
    "        self.__activation_func = activation_func\n",
    "\n",
    "    def add_neuron(self, neuron):\n",
    "        self.__neurons.append(neuron)\n",
    "\n",
    "    def get_neurons(self):\n",
    "        return self.__neurons\n",
    "    \n",
    "    def get_type(self):\n",
    "        return self.__type\n",
    "    \n",
    "    def get_activation_func(self):\n",
    "        return self.__activation_func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(\n",
    "        self, \n",
    "        layer: Layer,\n",
    "        weight: list,\n",
    "        bias: list, \n",
    "    ):\n",
    "        self.__layer: Layer = layer\n",
    "        self.__weight: list = weight\n",
    "        self.__bias: list = bias\n",
    "        self.__net: float = 0.0\n",
    "        self.__value: float = 0.0\n",
    "\n",
    "    def activate(self):\n",
    "        if self.__layer.get_activation_func() == ActivationFuncEnum.SIGMOID.value:\n",
    "            self.__value = 1 / (1 + math.exp(-self.__net))\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.LINEAR.value:\n",
    "            self.__value = self.__net\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.RELU.value:\n",
    "            self.__value = max(0, self.__net)\n",
    "        elif self.__layer.get_activation_func() == ActivationFuncEnum.SOFTMAX.value:\n",
    "            layer_neurons: list = self.__layer.get_neurons()\n",
    "            exp_sum: float = 0.0\n",
    "\n",
    "            for neuron in layer_neurons:\n",
    "                exp_sum += math.exp(neuron.get_net())\n",
    "\n",
    "            self.__value = math.exp(self.__net) / exp_sum\n",
    "\n",
    "    def set_value(self, value):\n",
    "        self.__value = value\n",
    "\n",
    "    def set_net(self, net):\n",
    "        self.__net = net\n",
    "\n",
    "    def get_value(self):\n",
    "        return self.__value\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.__net\n",
    "\n",
    "    def get_weight(self, index):\n",
    "        return self.__weight[index]\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.__weight\n",
    "\n",
    "    def get_bias(self):\n",
    "        return self.__bias\n",
    "    \n",
    "    def get_layer(self):\n",
    "        return self.__layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNGraph:\n",
    "    def __init__(self, file_config_path: str):\n",
    "        self.file_path = file_config_path\n",
    "        self.config = None\n",
    "\n",
    "        self.layers: list[Layer] = []\n",
    "        self.build_ann_graph()\n",
    "\n",
    "    def build_ann_graph(self):\n",
    "        self.config = FileUtility.import_json(self.file_path)\n",
    "        layers = self.config[\"layers\"]\n",
    "\n",
    "        for layer in layers:\n",
    "            # Untuk setiap layer, persiapkan neuronnya\n",
    "            curr_layer = Layer([], layer[\"type\"], layer[\"activation_func\"])\n",
    "\n",
    "            for neuron_data in layer[\"neurons\"]:\n",
    "                neuron = self.__generate_neuron_data(curr_layer, neuron_data)\n",
    "                curr_layer.add_neuron(neuron)\n",
    "\n",
    "            self.layers.append(curr_layer)\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        for i in range(len(input_data)):\n",
    "            # Masukkan input_data ke neuron di input layer\n",
    "            neuron: Neuron = self.layers[0].get_neurons()[i]\n",
    "            neuron.set_value(input_data[i])\n",
    "\n",
    "        self.__activate_all_neurons()\n",
    "\n",
    "        return\n",
    "\n",
    "    def print_details(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(\"--------------------\")\n",
    "            print(f\"Layer {i+1} ({layer.get_type()})\")\n",
    "            if layer.get_type() != LayerEnum.INPUT.value:\n",
    "                print(f\"Activation function: {layer.get_activation_func()}\")\n",
    "            print(\"--------------------\")\n",
    "            if layer.get_type() != LayerEnum.INPUT.value:\n",
    "                for j, neuron in enumerate(layer.get_neurons()):\n",
    "                    print(f\"[Neuron {j+1}] Net:\", neuron.get_net())\n",
    "                    print(f\"[Neuron {j+1}] Value:\", neuron.get_value())\n",
    "            else:\n",
    "                for j, neuron in enumerate(layer.get_neurons()):\n",
    "                    print(f\"[Neuron {j+1}] is supplied value of {neuron.get_value()}\")\n",
    "            print(\"\")\n",
    "\n",
    "    def __generate_neuron_data(self, layer: Layer, neuron_data):\n",
    "        weights: list = []\n",
    "        bias: list = []\n",
    "\n",
    "        if (layer.get_type() == LayerEnum.HIDDEN.value or layer.get_type() == LayerEnum.OUTPUT.value):\n",
    "            weights = neuron_data[\"weights\"]\n",
    "            bias = neuron_data[\"bias\"]\n",
    "\n",
    "        return Neuron(layer, weights, bias)\n",
    "    \n",
    "    def __activate_all_neurons(self):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if layer.get_type() == LayerEnum.INPUT.value:\n",
    "                continue # Tidak perlu activate untuk input layer\n",
    "\n",
    "            previous_layer = self.layers[i - 1]\n",
    "            for neuron in layer.get_neurons():\n",
    "                self.__calculate_neuron_net(neuron, previous_layer)\n",
    "                neuron.activate()\n",
    "\n",
    "        return\n",
    "\n",
    "    def __calculate_neuron_net(self, neuron: Neuron, previous_layer: Layer):\n",
    "        total = 0.0\n",
    "\n",
    "        for i, prev_neuron in enumerate(previous_layer.get_neurons()):\n",
    "            # i + 1 karena i = 0 adalah weight dari bias\n",
    "            total += prev_neuron.get_value() * neuron.get_weight(i + 1)\n",
    "\n",
    "        total += neuron.get_bias() * neuron.get_weight(0)\n",
    "\n",
    "        neuron.set_net(total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Untuk x1 = 0 dan x2 = 0:**\n",
      "--------------------\n",
      "Layer 1 (INPUT)\n",
      "--------------------\n",
      "[Neuron 1] is supplied value of 0\n",
      "[Neuron 2] is supplied value of 0\n",
      "\n",
      "--------------------\n",
      "Layer 2 (HIDDEN)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: -10.0\n",
      "[Neuron 1] Value: 4.5397868702434395e-05\n",
      "[Neuron 2] Net: 30.0\n",
      "[Neuron 2] Value: 0.9999999999999065\n",
      "\n",
      "--------------------\n",
      "Layer 3 (OUTPUT)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: -9.999092042627819\n",
      "[Neuron 1] Value: 4.543910487654591e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = ANNGraph(\"config/xor_sigmoid.json\")\n",
    "print(\"**Untuk x1 = 0 dan x2 = 0:**\")\n",
    "graph.predict([0, 0])\n",
    "graph.print_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Untuk x1 = 0 dan x2 = 1:**\n",
      "--------------------\n",
      "Layer 1 (INPUT)\n",
      "--------------------\n",
      "[Neuron 1] is supplied value of 0\n",
      "[Neuron 2] is supplied value of 1\n",
      "\n",
      "--------------------\n",
      "Layer 2 (HIDDEN)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: 10.0\n",
      "[Neuron 1] Value: 0.9999546021312976\n",
      "[Neuron 2] Net: 10.0\n",
      "[Neuron 2] Value: 0.9999546021312976\n",
      "\n",
      "--------------------\n",
      "Layer 3 (OUTPUT)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: 9.998184085251907\n",
      "[Neuron 1] Value: 0.999954519621495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**Untuk x1 = 0 dan x2 = 1:**\")\n",
    "graph.predict([0, 1])\n",
    "graph.print_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Untuk x1 = 1 dan x2 = 0:**\n",
      "--------------------\n",
      "Layer 1 (INPUT)\n",
      "--------------------\n",
      "[Neuron 1] is supplied value of 1\n",
      "[Neuron 2] is supplied value of 0\n",
      "\n",
      "--------------------\n",
      "Layer 2 (HIDDEN)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: 10.0\n",
      "[Neuron 1] Value: 0.9999546021312976\n",
      "[Neuron 2] Net: 10.0\n",
      "[Neuron 2] Value: 0.9999546021312976\n",
      "\n",
      "--------------------\n",
      "Layer 3 (OUTPUT)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: 9.998184085251907\n",
      "[Neuron 1] Value: 0.999954519621495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**Untuk x1 = 1 dan x2 = 0:**\")\n",
    "graph.predict([1, 0])\n",
    "graph.print_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Untuk x1 = 1 dan x2 = 1:**\n",
      "--------------------\n",
      "Layer 1 (INPUT)\n",
      "--------------------\n",
      "[Neuron 1] is supplied value of 1\n",
      "[Neuron 2] is supplied value of 1\n",
      "\n",
      "--------------------\n",
      "Layer 2 (HIDDEN)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: 30.0\n",
      "[Neuron 1] Value: 0.9999999999999065\n",
      "[Neuron 2] Net: -10.0\n",
      "[Neuron 2] Value: 4.5397868702434395e-05\n",
      "\n",
      "--------------------\n",
      "Layer 3 (OUTPUT)\n",
      "Activation function: SIGMOID\n",
      "--------------------\n",
      "[Neuron 1] Net: -9.999092042627819\n",
      "[Neuron 1] Value: 4.543910487654591e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**Untuk x1 = 1 dan x2 = 1:**\")\n",
    "graph.predict([1, 1])\n",
    "graph.print_details()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
